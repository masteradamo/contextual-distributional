import collections
import numpy as np
from nltk.stem import SnowballStemmer

fold = "/home/folder/"

fr = fold + "wordus.txt"
fv = fold + "vectors/"
fd = fold + "dimensions/"

def translater():
    rt = [x.split("::")[0] for x in open(fr,'r').readlines()]
    tr = {rt[n]:str(n) for n in range(len(rt))}
    return tr,rt

def indyer(inds,ext):
    outs = set()
    pt = 0
    while len(outs) < ext:
        print "LOUT",outs,pt,len(outs)
        pt  += max(1,(ext-len(outs))/len(inds))
        outs.update([x for y in inds for x in y[:pt]])
    return outs

def spacer(words,ext):
    wecs = []
    vecs = collections.defaultdict(list)
    inds = []
    for word in words:
        indl = []
        vec = collections.defaultdict(float)
        for pair in open(fv+word+".txt",'r').readlines():
            vecs[pair.split("::")[0]].append(float(pair.split("::")[1]))
            indl.append((float(pair.split("::")[1]),pair.split("::")[0]))
            vec[pair.split("::")[0]] = float(pair.split("::")[1])
        inds.append([x[1] for x in sorted(indl,reverse=True)[:ext]])
        wecs.append(vec)
    joint = [x[1] for x in sorted([(sum(vecs[y]),y) for y in vecs if len(vecs[y])==len(words)],reverse=True)][:ext]
    simple = [x[1] for x in sorted([(sum(vecs[y]),y) for y in vecs],reverse=True)][:ext]
    indy = indyer(inds,ext)
    return [simple,joint,indy],wecs

def measurer(space,vecs,words):
    mean = {x:(sum([y[x] for y in vecs])/len(words)) for x in space}
    morm = np.sqrt(sum([mean[x]**2 for x in mean]))
    vorm = np.mean([np.sqrt(sum([y[x]**2 for x in space])) for y in vecs])
    rat = vorm/morm
    print "RAT",rat
    mean = {x:mean[x]*rat for x in mean}
    norms = collections.defaultdict(float)
    dists = {}
    seen = 0.0
    for dim in space:
        pairs = open(fd+dim+".txt",'r').readlines()
        hits = {}
        for pt in pairs:
            vec = pt.split("::")[0]
            val = float(pt.split("::")[1])
            if pt.split("::")[0] not in words:
                norms[vec] += val**2
                if vec not in dists:
                    dists[vec] = seen
                dists[vec] += (mean[dim]-val)**2
                hits[vec] = True
        for item in dists:
            if item not in hits:
                dists[item] += mean[dim]**2
        seen += mean[dim]**2
    norm = [x[1] for x in sorted([(norms[y],y) for y in norms],reverse=True)]
    dist = [x[1] for x in sorted([(dists[y],y) for y in dists])]
    return norm,dist

def taker(words,ext,lim):
    words = [tr[x] for x in words]
    spaces,vecs = spacer(words,ext)
    print "SPACES PROJECTED"
    names = ["SIMPLE","JOINT","INDY"]
    print ""
    for n in range(len(spaces)):
        print names[n]
        norm,dist = measurer(spaces[n],vecs,words)
#        print "DIMENSIONS",[(rt[int(x)],[vecs[y][x] for y in range(len(words))]) for x in spaces[n]],len(spaces[n])
        print "BY NORM",[rt[int(x)] for x in norm[:lim]]
        print "BY DISTANCE",[rt[int(x)] for x in dist[:lim]]
        print ""

tr,rt = translater()
print "TRANSLATERS BUILT"
words = []
while True:
    x = raw_input("WORD: ")
    if x != "":
        if x in tr:
            if int(tr[x]) < 200000:
                words.append(x)
            else:
                print "NOT IN VOCABULARY (ranked " + str(tr[x]) + ")"
        else:
            print "NOT A WORD"
    else:
        dx = int(raw_input("DIMENSIONS: "))
        vx = int(raw_input("VECTORS: "))
        taker(words,dx,vx)
        words = []
